{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-",
      "formats": "ipynb,py:percent",
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "IR-project-google-brain-trax-library-intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prateekchandrajha/ir-mini-project/blob/main/IR_project_google_brain_trax_library_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm9D3IN5krZL"
      },
      "source": [
        "# Introduction to Trax Library Maintained by Google Brain Team\n",
        "\n",
        "In this code walk-through we'll cover the fundamentals of the Trax framework and learn about its basic building blocks including classes, sub-classes and data generators.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXgCqSTGkrZb"
      },
      "source": [
        "## Background\n",
        "\n",
        "### Why Should Someone Use Trax and not TensorFlow, Keras, Caffe or PyTorch? (Also explains why we used it for our IR Mini-Project)\n",
        "\n",
        "TensorFlow and PyTorch are both extensive frameworks that can do almost anything in deep learning. They offer a lot of flexibility, but that often means verbosity of syntax and extra time to code.\n",
        "\n",
        "Trax is much more concise. It runs on a TensorFlow backend but allows you to train models with 1 line commands. Trax also runs end to end, allowing you to get data, model and train all with a single terse statements. This means you can focus on learning, instead of spending hours on the idiosyncrasies of big framework implementation. \n",
        "\n",
        "### Why not Keras then? Elaborate More?\n",
        "\n",
        "Keras is now part of Tensorflow itself from 2.0 onwards. Also, trax is good for implementing new state of the art algorithms like Transformers, Reformers, BERT because it is actively maintained by Google Brain Team for advanced deep learning tasks. It runs smoothly on CPUs,GPUs and TPUs as well with comparatively lesser modifications in code.\n",
        "\n",
        "### How to Code Neural Networks in Trax?\n",
        "Building models in Trax relies on 2 key concepts:- **layers** and **combinators**.\n",
        "\n",
        "Trax layers are simple objects that process data and perform computations. They can be chained together into composite layers using Trax combinators, allowing you to build layers and models of any complexity.\n",
        "\n",
        "### Trax, JAX, TensorFlow and Tensor2Tensor\n",
        "\n",
        "You already know that Trax uses Tensorflow as a backend, but it also uses the JAX library to speed up computation too. You can view JAX as an enhanced and optimized version of numpy. \n",
        "\n",
        "**Sometimes you'll find us importing `import trax.fastmath.numpy as np`. So when we call `np` we are really calling Traxâ€™s version of numpy that is compatible with JAX.**\n",
        "\n",
        "As a result of this, where one used to encounter the type `numpy.ndarray` now you will find the type `jax.interpreters.xla.DeviceArray`.\n",
        "\n",
        "Tensor2Tensor is another name we have heard. It started as an end to end solution much like how Trax is designed, but it grew unwieldy and complicated. So once can view Trax as the new improved version that operates much faster and simpler.\n",
        "\n",
        "### More Resources & References:\n",
        "\n",
        "- Trax source code can be found on Github: [Trax](https://github.com/google/trax)\n",
        "- Read more about JAX library over here: [JAX](https://jax.readthedocs.io/en/latest/index.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7azrmjAgkrZe"
      },
      "source": [
        "## Installing Trax\n",
        "\n",
        "Trax has dependencies on JAX and some libraries like JAX which are yet to be supported in [Windows](https://github.com/google/jax/blob/1bc5896ee4eab5d7bb4ec6f161d8b2abb30557be/README.md#installation).\n",
        "\n",
        "Official maintained documentation - [trax-ml](https://trax-ml.readthedocs.io/en/latest/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7b-ssgYkrZg"
      },
      "source": [
        "# !pip install trax==1.3.1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM16P1ODkrZh"
      },
      "source": [
        "\n",
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "h8wIjmyakrZi"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np  # regular ol' numpy\n",
        "\n",
        "from trax import layers as tl  # core building block\n",
        "from trax import shapes  # data signatures: dimensionality and type\n",
        "from trax import fastmath  # uses jax, offers numpy on steroids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "XNIJpUNgkrZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087ade9e-c42d-4d74-9746-dad19a14ffc5"
      },
      "source": [
        "# Trax version 1.3.1 or better \n",
        "!pip list | grep trax"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trax                          1.3.1                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkyYgw3ikrZm"
      },
      "source": [
        "## Layers\n",
        "Layers are the core building blocks in Trax so they are the base classes.\n",
        "\n",
        "They take inputs, compute functions/custom calculations and return outputs.\n",
        "\n",
        "We can also inspect layer properties. Let us do a code walk-through.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUppQfAokrZn"
      },
      "source": [
        "### Relu Layer\n",
        "First we'll see how to build a Relu activation function as a layer. A layer like this is one of the simplest types. Notice there is no object initialization so it works just like a math function.\n",
        "\n",
        "**Note: Activation functions are also layers in Trax, which might look odd if you have been using other frameworks for a longer time. Traditionally layers in deep learning refer to layers of neural networks. In Trax, on the other hand, everything can be considered and implemented as a layer.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "p5Wfl3RmkrZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd99b4e5-58f5-4d09-d561-3b7cbbbb9339"
      },
      "source": [
        "# Layers\n",
        "# Create a relu trax layer\n",
        "relu = tl.Relu()\n",
        "\n",
        "# Inspect properties\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", relu.name)\n",
        "print(\"expected inputs :\", relu.n_in)\n",
        "print(\"promised outputs :\", relu.n_out, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "x = np.array([-2, -1, 0, 1, 2])\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x :\", x, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "y = relu(x)\n",
        "print(\"-- Outputs --\")\n",
        "print(\"y :\", y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Properties --\n",
            "name : Relu\n",
            "expected inputs : 1\n",
            "promised outputs : 1 \n",
            "\n",
            "-- Inputs --\n",
            "x : [-2 -1  0  1  2] \n",
            "\n",
            "-- Outputs --\n",
            "y : [0 0 0 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfQG9Ol5krZo"
      },
      "source": [
        "### Concatenate Layer\n",
        "Now we see how to build a layer that takes 2 inputs. Notice the change in the expected inputs property from 1 to 2. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "6hAe81XXkrZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa058df-1a73-43ee-c132-94fe873b3dc0"
      },
      "source": [
        "# Create a concatenate trax layer\n",
        "concat = tl.Concatenate()\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", concat.name)\n",
        "print(\"expected inputs :\", concat.n_in)\n",
        "print(\"promised outputs :\", concat.n_out, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "x1 = np.array([-10, -20, -30])\n",
        "x2 = x1 / -10\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x1 :\", x1)\n",
        "print(\"x2 :\", x2, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "y = concat([x1, x2])\n",
        "print(\"-- Outputs --\")\n",
        "print(\"y :\", y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Properties --\n",
            "name : Concatenate\n",
            "expected inputs : 2\n",
            "promised outputs : 1 \n",
            "\n",
            "-- Inputs --\n",
            "x1 : [-10 -20 -30]\n",
            "x2 : [1. 2. 3.] \n",
            "\n",
            "-- Outputs --\n",
            "y : [-10. -20. -30.   1.   2.   3.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kfyNMAgkrZq"
      },
      "source": [
        "## Layers are Configurable\n",
        "We can change the default settings of layers. For example, we can change the expected inputs for a concatenate layer from 2 to 3 using the optional parameter `n_items`. This is very useful in practical world."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "05fnXJfgkrZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d93648-a399-4295-e567-fad56f0609c4"
      },
      "source": [
        "# Configure a concatenate layer\n",
        "concat_3 = tl.Concatenate(n_items=3)  # configure the layer's expected inputs\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", concat_3.name)\n",
        "print(\"expected inputs :\", concat_3.n_in)\n",
        "print(\"promised outputs :\", concat_3.n_out, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "x1 = np.array([-10, -20, -30])\n",
        "x2 = x1 / -10\n",
        "x3 = x2 * 0.99\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x1 :\", x1)\n",
        "print(\"x2 :\", x2)\n",
        "print(\"x3 :\", x3, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "y = concat_3([x1, x2, x3])\n",
        "print(\"-- Outputs --\")\n",
        "print(\"y :\", y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Properties --\n",
            "name : Concatenate\n",
            "expected inputs : 3\n",
            "promised outputs : 1 \n",
            "\n",
            "-- Inputs --\n",
            "x1 : [-10 -20 -30]\n",
            "x2 : [1. 2. 3.]\n",
            "x3 : [0.99 1.98 2.97] \n",
            "\n",
            "-- Outputs --\n",
            "y : [-10.   -20.   -30.     1.     2.     3.     0.99   1.98   2.97]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DNg8FHxkrZt"
      },
      "source": [
        "## Layers can have Weights\n",
        "Some layer types include mutable weights and biases that are used in computation and training. Layers of this type require initialization before use.\n",
        "\n",
        "For example the `LayerNorm` layer calculates normalized data, that is also scaled by weights and biases. During initialization you pass the data shape and data type of the inputs, so the layer can initialize compatible arrays of weights and biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "MVd87pYOkrZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee75338-1dbb-4c46-991f-be38afa6e4ca"
      },
      "source": [
        "# Layer initialization\n",
        "norm = tl.LayerNorm()\n",
        "# You first must know what the input data will look like\n",
        "x = np.array([0, 1, 2, 3], dtype=\"float\")\n",
        "\n",
        "# Use the input data signature to get shape and type for initializing weights and biases\n",
        "norm.init(shapes.signature(x)) # We need to convert the input datatype from usual tuple to trax ShapeDtype\n",
        "\n",
        "print(\"Normal shape:\",x.shape, \"Data Type:\",type(x.shape))\n",
        "print(\"Shapes Trax:\",shapes.signature(x),\"Data Type:\",type(shapes.signature(x)))\n",
        "\n",
        "# Inspect properties\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", norm.name)\n",
        "print(\"expected inputs :\", norm.n_in)\n",
        "print(\"promised outputs :\", norm.n_out)\n",
        "# Weights and biases\n",
        "print(\"weights :\", norm.weights[0])\n",
        "print(\"biases :\", norm.weights[1], \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x :\", x)\n",
        "\n",
        "# Outputs\n",
        "y = norm(x)\n",
        "print(\"-- Outputs --\")\n",
        "print(\"y :\", y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal shape: (4,) Data Type: <class 'tuple'>\n",
            "Shapes Trax: ShapeDtype{shape:(4,), dtype:float64} Data Type: <class 'trax.shapes.ShapeDtype'>\n",
            "-- Properties --\n",
            "name : LayerNorm\n",
            "expected inputs : 1\n",
            "promised outputs : 1\n",
            "weights : [1. 1. 1. 1.]\n",
            "biases : [0. 0. 0. 0.] \n",
            "\n",
            "-- Inputs --\n",
            "x : [0. 1. 2. 3.]\n",
            "-- Outputs --\n",
            "y : [-1.3416404  -0.44721344  0.44721344  1.3416404 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtKE2bfYkrZv"
      },
      "source": [
        "## Custom Layers & Functions\n",
        "This is where things start getting much more interesting than in Keras & Pytorch! Here we can create our own custom layers too and define custom functions for computations by using `tl.Fn`. Let us see how."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaYP6nh4krZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f5808b-b28d-4981-b898-3dbe9fdd6594"
      },
      "source": [
        "help(tl.Fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function Fn in module trax.layers.base:\n",
            "\n",
            "Fn(name, f, n_out=1)\n",
            "    Returns a layer with no weights that applies the function `f`.\n",
            "    \n",
            "    `f` can take and return any number of arguments, and takes only positional\n",
            "    arguments -- no default or keyword arguments. It often uses JAX-numpy (`jnp`).\n",
            "    The following, for example, would create a layer that takes two inputs and\n",
            "    returns two outputs -- element-wise sums and maxima:\n",
            "    \n",
            "        `Fn('SumAndMax', lambda x0, x1: (x0 + x1, jnp.maximum(x0, x1)), n_out=2)`\n",
            "    \n",
            "    The layer's number of inputs (`n_in`) is automatically set to number of\n",
            "    positional arguments in `f`, but you must explicitly set the number of\n",
            "    outputs (`n_out`) whenever it's not the default value 1.\n",
            "    \n",
            "    Args:\n",
            "      name: Class-like name for the resulting layer; for use in debugging.\n",
            "      f: Pure function from input tensors to output tensors, where each input\n",
            "          tensor is a separate positional arg, e.g., `f(x0, x1) --> x0 + x1`.\n",
            "          Output tensors must be packaged as specified in the `Layer` class\n",
            "          docstring.\n",
            "      n_out: Number of outputs promised by the layer; default value 1.\n",
            "    \n",
            "    Returns:\n",
            "      Layer executing the function `f`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "-Zmu_EXvkrZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078bb4e0-654a-4b97-e008-e404641586aa"
      },
      "source": [
        "# Define a custom layer\n",
        "# In this example we will create a simple layer to just calculate the input times 2\n",
        "\n",
        "def TimesTwo():\n",
        "    layer_name = \"TimesTwo\" # Trax uses this to identify the layer\n",
        "\n",
        "    # Custom function for the custom layer\n",
        "    def func(x):\n",
        "        return x * 2\n",
        "\n",
        "    return tl.Fn(layer_name, func)\n",
        "\n",
        "\n",
        "# Testing\n",
        "times_two = TimesTwo()\n",
        "\n",
        "# Inspect properties\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", times_two.name)\n",
        "print(\"expected inputs :\", times_two.n_in)\n",
        "print(\"promised outputs :\", times_two.n_out, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "x = np.array([1, 2, 3])\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x :\", x, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "y = times_two(x)\n",
        "print(\"-- Outputs --\")\n",
        "print(\"y :\", y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Properties --\n",
            "name : TimesTwo\n",
            "expected inputs : 1\n",
            "promised outputs : 1 \n",
            "\n",
            "-- Inputs --\n",
            "x : [1 2 3] \n",
            "\n",
            "-- Outputs --\n",
            "y : [2 4 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni83Z1PMkrZx"
      },
      "source": [
        "## Combinators\n",
        "We can also combine separate simple layers to build more complex layers. As we highlighted above, Trax provides a set of objects named combinator layers to make this happen. Combinators are themselves layers, so behavior commutes in a way.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3OzQoKlkrZz"
      },
      "source": [
        "### Serial Combinator\n",
        "This is the most common and easiest to use combinator layer. For example we could build a simple neural network by combining layers into a single layer using the `Serial` combinator. This new layer then acts just like a single layer, so you can inspect intputs, outputs and weights. Or even combine it into another layer! Combinators can then be used as trainable neural network models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N97AL8GjkrZ0"
      },
      "source": [
        "# help(tl.Serial)\n",
        "# help(tl.Parallel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Lia6bfy2krZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a80f07-017b-44e8-d67a-984134172aae"
      },
      "source": [
        "# Serial combinator\n",
        "serial = tl.Serial(\n",
        "    tl.LayerNorm(),         # normalize input values\n",
        "    tl.Relu(),              # convert negative values to zero using Relu activation function\n",
        "    times_two,              # the custom layer we created above, multiplies the input recieved from above by 2\n",
        "\n",
        "#     tl.Dense(n_units=2),  # we can add more layers\n",
        "#     tl.Dense(n_units=1),  # Binary classification\n",
        "#     tl.LogSoftmax()       # Yes, LogSoftmax is also a layer\n",
        ")\n",
        "\n",
        "# Initialization\n",
        "x = np.array([-2, -1, 0, 1, 2]) #input\n",
        "serial.init(shapes.signature(x)) #initialising serial instance\n",
        "\n",
        "print(\"-- Serial Model --\")\n",
        "print(serial,\"\\n\")\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", serial.name)\n",
        "print(\"sublayers :\", serial.sublayers)\n",
        "print(\"expected inputs :\", serial.n_in)\n",
        "print(\"promised outputs :\", serial.n_out)\n",
        "print(\"weights & biases:\", serial.weights, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x :\", x, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "y = serial(x)\n",
        "print(\"-- Outputs --\")\n",
        "print(\"y :\", y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Serial Model --\n",
            "Serial[\n",
            "  LayerNorm\n",
            "  Relu\n",
            "  TimesTwo\n",
            "] \n",
            "\n",
            "-- Properties --\n",
            "name : Serial\n",
            "sublayers : [LayerNorm, Relu, TimesTwo]\n",
            "expected inputs : 1\n",
            "promised outputs : 1\n",
            "weights & biases: [(DeviceArray([1, 1, 1, 1, 1], dtype=int32), DeviceArray([0, 0, 0, 0, 0], dtype=int32)), (), ()] \n",
            "\n",
            "-- Inputs --\n",
            "x : [-2 -1  0  1  2] \n",
            "\n",
            "-- Outputs --\n",
            "y : [0.        0.        0.        1.4142132 2.8284264]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kScoqbbkrZ3"
      },
      "source": [
        "## JAX\n",
        "When working with `trax` we should be careful regarding which numpy have we been using, the regular old numpy or Trax's JAX compatible numpy. Both tend to use the alias np for importing so we will mention whenever we use one kind of numpy and not another.\n",
        "\n",
        "**Note:There are certain things which are still not possible in fastmath.numpy which can be done in normal old numpy so we will sometimes switch between them to get our work done.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "AosvXnKMkrZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212e8dea-f3c5-4d2c-8247-62c03248c7ce"
      },
      "source": [
        "# Numpy vs fastmath.numpy have different data types\n",
        "# Regular old numpy\n",
        "\n",
        "x_numpy = np.array([1, 2, 3])\n",
        "print(\"good old numpy : \", type(x_numpy), \"\\n\")\n",
        "\n",
        "# Fastmath and jax numpy\n",
        "x_jax = fastmath.numpy.array([1, 2, 3])\n",
        "print(\"jax trax numpy : \", type(x_jax))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "good old numpy :  <class 'numpy.ndarray'> \n",
            "\n",
            "jax trax numpy :  <class 'jax.interpreters.xla._DeviceArray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvuqEEDgsHlD"
      },
      "source": [
        "\r\n",
        "# Data generators in Trax\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlQ7oSOPslPU"
      },
      "source": [
        "In Python, a generator is a function that behaves like an iterator. It will return the next item. Here is a [link](https://wiki.python.org/moin/Generators) to delve deeper into python generators. In many AI applications, it is advantageous to have a data generator to handle loading and transforming data for different applications. Every deep learnign framework has to have some sort of a dataloader mechanism.\r\n",
        "\r\n",
        "We will now implement a custom data generator. In the following code walk-through, we use a set of samples `a`, to derive a new set of samples, with more elements than the original set. This demonstrates how a data generator can be manipulated.\r\n",
        "\r\n",
        "**Note: Due attention should be paid to the usage of list `lines_index` and variable `index` to traverse the original list.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwRmpEf3rYnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6d14b8-0530-41c9-9dc7-01ba7fe08514"
      },
      "source": [
        "import random \r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# Example of traversing a list of indexes to create a circular list\r\n",
        "a = [1, 2, 3, 4]\r\n",
        "b = [0] * 10\r\n",
        "\r\n",
        "a_size = len(a)\r\n",
        "b_size = len(b)\r\n",
        "\r\n",
        "lines_index = [*range(a_size)] # is equivalent to list comprehension [i for i in range(0, a_size)], the difference being the advantage of using * to pass values of range iterator to list directly\r\n",
        "index = 0                      # similar to index in data_generator below\r\n",
        "for i in range(b_size):        # `b` is longer than `a` forcing a wrap\r\n",
        "    \r\n",
        "    # We wrap by resetting index to 0 so the sequences circle back at the end to point to the first index\r\n",
        "    if index >= a_size:\r\n",
        "        index = 0\r\n",
        "    \r\n",
        "    b[i] = a[lines_index[index]]     #  `indexes_list[index]` point to a index of a. Store the result in b\r\n",
        "    index += 1\r\n",
        "    \r\n",
        "print(b)\r\n",
        "# so as you see in the output below, after traversing the list from 1 to 4, it starts back at 1 and carries on till we exhaust the traversal"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 1, 2, 3, 4, 1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYIJdqdRtrxl"
      },
      "source": [
        "## Shuffling the data order\r\n",
        "\r\n",
        "In the next code walk-through, we will do the same as before, but shuffling the order of the elements in the output list. We should note that here, our strategy of traversing using `lines_index` and `index` becomes very important, because we can simulate a shuffle in the input data, without doing that in reality. So simply put, data is shuffled in output without the original data order being shuffled.\r\n",
        "\r\n",
        "**So why does it matter at all?**\r\n",
        "\r\n",
        "**In deep learning parlance, we call it 1 epoch each time a deep learning training algorithm passes over all the training examples. Shuffling the examples for each epoch is known to reduce variance, making the models more generalizable and less prone to overfitting.**\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KBb1Y_ItFq7",
        "outputId": "0e521666-4d33-4547-a866-da00d5e74252"
      },
      "source": [
        "# Example of traversing a list of indexes to create a circular list\r\n",
        "a = [1, 2, 3, 4]\r\n",
        "b = []\r\n",
        "\r\n",
        "a_size = len(a)\r\n",
        "b_size = 10\r\n",
        "\r\n",
        "lines_index = [*range(a_size)]\r\n",
        "print(\"Original order of index:\", lines_index)\r\n",
        "\r\n",
        "# if we shuffle the index_list we can change the order of our circular list\r\n",
        "# without modifying the order or our original data\r\n",
        "\r\n",
        "random.shuffle(lines_index) # Shuffle the order\r\n",
        "print(\"Shuffled order of index:\", lines_index)\r\n",
        "\r\n",
        "print(\"New value order for first batch:\", [a[index] for index in lines_index]) # using list comprehension\r\n",
        "\r\n",
        "batch_counter = 1\r\n",
        "index = 0                # similar to index in data_generator below\r\n",
        "\r\n",
        "for i in range(b_size):  # `b` is longer than `a` forcing a wrap\r\n",
        "    # We wrap by resetting index to 0\r\n",
        "    if index >= a_size:\r\n",
        "        index = 0\r\n",
        "        batch_counter += 1\r\n",
        "        random.shuffle(lines_index) # Re-shuffle the order\r\n",
        "        print(\"\\nShuffled Indexes for Batch No.{} :{}\".format(batch_counter,lines_index))\r\n",
        "        print(\"Values for Batch No.{} :{}\".format(batch_counter,[a[index] for index in lines_index]))\r\n",
        "    \r\n",
        "    b.append(a[lines_index[index]])     #  `indexes_list[index]` point to a index of a. Store the result in b\r\n",
        "    index += 1\r\n",
        "print()    \r\n",
        "print(\"Final value of b:\", b)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original order of index: [0, 1, 2, 3]\n",
            "Shuffled order of index: [3, 2, 1, 0]\n",
            "New value order for first batch: [4, 3, 2, 1]\n",
            "\n",
            "Shuffled Indexes for Batch No.2 :[3, 1, 2, 0]\n",
            "Values for Batch No.2 :[4, 2, 3, 1]\n",
            "\n",
            "Shuffled Indexes for Batch No.3 :[1, 3, 2, 0]\n",
            "Values for Batch No.3 :[2, 4, 3, 1]\n",
            "\n",
            "Final value of b: [4, 3, 2, 1, 4, 2, 3, 1, 2, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-c4K1S2u74-"
      },
      "source": [
        "## Final Custom Data Generator Code Walk-Through\r\n",
        "\r\n",
        "So here we try and implement a data generator function that takes in `batch_size, x, y, shuffle` where x could be a large list of samples, and y is a list of the tags associated with those samples. Our generator should return a subset of those inputs in a tuple of two arrays `(X,Y)`. Each is an array of dimension (`batch_size`). If `shuffle=True`, the data will be traversed in a random form in each subsequent epoch (defined above).\r\n",
        "\r\n",
        "**Implementation Details:**\r\n",
        "\r\n",
        "This code as an outer loop looks like this: \r\n",
        "```\r\n",
        "while True:  \r\n",
        "...  \r\n",
        "yield((X,Y))  \r\n",
        "```\r\n",
        "\r\n",
        "Which runs continuously in the fashion of generators, pausing when yielding the next values. We will generate a batch_size output on each pass of this loop.    \r\n",
        "\r\n",
        "It has an inner loop that stores in temporal lists `(X, Y)` i.e. the data samples to be included in the next batch of yielding.\r\n",
        "\r\n",
        "There are 3 slightly out of the ordinary features which should be given due thought:\r\n",
        "\r\n",
        "1. The first is the use of a list of a predefined size to store the data for each batch. Using a predefined size list reduces the computation time if the elements in the array are of a fixed size, like numbers. If the elements are of different sizes, it is better to use an empty array and append one element at a time during the loop. When you know things in advance, go for a list of predefined size.\r\n",
        "\r\n",
        "2. The second is tracking the current location in the incoming lists of samples. Generator's variables hold their values between invocations/yielding, so we create an `index` variable, initialize to zero, and increment by one for each sample included in a batch. However, we do not use the `index` to access the positions of the list of sentences directly. Instead, we use it to select one index from a list of indexes. In this way, we can change the order in which we traverse our original list, keeping untouched/unblemished our original list data.  \r\n",
        "\r\n",
        "3. The third relates to wrapping. Because `batch_size` and the length of the input lists are not aligned, gathering a batch_size group of inputs may involve wrapping back to the beginning of the input loop. In our approach, it is just enough to reset the `index` to 0. We can re-shuffle the list of indexes to produce different batches in each subsequent epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW48-f67uMbE"
      },
      "source": [
        "def data_generator(batch_size, data_x, data_y, shuffle=True):\r\n",
        "    '''\r\n",
        "      Input: \r\n",
        "        batch_size - integer describing the batch size\r\n",
        "        data_x - list containing samples\r\n",
        "        data_y - list containing labels\r\n",
        "        shuffle - Shuffle the data order\r\n",
        "      Output:\r\n",
        "        a tuple containing 2 elements:\r\n",
        "        X - list of dim (batch_size) of samples\r\n",
        "        Y - list of dim (batch_size) of labels\r\n",
        "    '''\r\n",
        "    \r\n",
        "    data_lng = len(data_x) # len(data_x) must be equal to len(data_y)\r\n",
        "    index_list = [*range(data_lng)] # Create a list with the ordered indexes of sample data\r\n",
        "    \r\n",
        "    \r\n",
        "    # If shuffle is set to true, we traverse the list in a random way\r\n",
        "    if shuffle:\r\n",
        "        random.shuffle(index_list) # Inplace shuffle of the list\r\n",
        "    \r\n",
        "    index = 0 # Start with the first element\r\n",
        "      \r\n",
        "    while True:\r\n",
        "        X = [0] * batch_size # We can create a list with batch_size elements. \r\n",
        "        Y = [0] * batch_size # We can create a list with batch_size elements. \r\n",
        "        \r\n",
        "        for i in range(batch_size):\r\n",
        "            \r\n",
        "            # Wrap the index each time that we reach the end of the list\r\n",
        "            if index >= data_lng:\r\n",
        "                index = 0\r\n",
        "                # Shuffle the index_list if shuffle is true\r\n",
        "                if shuffle:\r\n",
        "                    rnd.shuffle(index_list) # re-shuffle the order\r\n",
        "            \r\n",
        "            X[i] = data_x[index_list[index]] # We set the corresponding element in x\r\n",
        "            Y[i] = data_y[index_list[index]] # We set the corresponding element in x\r\n",
        "           \r\n",
        "            index += 1\r\n",
        "        \r\n",
        "        yield((X, Y))\r\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTaK-Om7wgaC",
        "outputId": "93586118-d5d0-44d3-9a44-e5009c879fd1"
      },
      "source": [
        "def testing_custom_data_generator():\r\n",
        "    x = [1, 2, 3, 4]\r\n",
        "    y = [xi ** 2 for xi in x]\r\n",
        "    \r\n",
        "    generator = data_generator(3, x, y, shuffle=False)\r\n",
        "\r\n",
        "    assert np.allclose(next(generator), ([1, 2, 3], [1, 4, 9])),  \"First batch does not match\"\r\n",
        "    assert np.allclose(next(generator), ([4, 1, 2], [16, 1, 4])), \"Second batch does not match\"\r\n",
        "    assert np.allclose(next(generator), ([3, 4, 1], [9, 16, 1])), \"Third batch does not match\"\r\n",
        "    assert np.allclose(next(generator), ([2, 3, 4], [4, 9, 16])), \"Fourth batch does not match\"\r\n",
        "\r\n",
        "    print(\"\\033[92mAll tests passed!\")\r\n",
        "\r\n",
        "testing_custom_data_generator()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92mAll tests passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8HFb0SokrZ5"
      },
      "source": [
        "## Summary\n",
        "Trax is a concise deep learning framework, built on TensorFlow, for end to end machine/deep learning. The key building blocks are layers and combinators. This code walk-through was to give a taste of the library our project is based upon. It also sets us up with some key custom layer and data generator intuitions to take forward into the next few submissions where we have built an end to end Neural Machine Translation model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJaOeJbuw70I"
      },
      "source": [
        "## Code References:\r\n",
        "- [Trax Layers Introduction](https://trax-ml.readthedocs.io/en/latest/notebooks/layers_intro.html)\r\n",
        "- [JAX, AKA NUMPY ON STEROIDS](https://iaml.it/blog/jax-intro-english)\r\n",
        "- [JAX is NumPy on the CPU, GPU, and TPU, with great automatic differentiation for high-performance machine learning research.](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html)\r\n",
        "- [You don't know JAX](https://colinraffel.com/blog/you-don-t-know-jax.html)\r\n",
        "- [Trax â€” Deep Learning with Clear Code and Speed](https://github.com/google/trax)"
      ]
    }
  ]
}