{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-",
      "formats": "ipynb,py:percent"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "IR-project-Stack-Semantics-Trax.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prateekchandrajha/ir-mini-project/blob/main/IR_project_Stack_Semantics_Trax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtC6QCk-85c9"
      },
      "source": [
        "# Stack Data Structure and Nuances in Trax Library (IR Mini-Project)\r\n",
        "# Stack Semantics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cQcm43h85dB"
      },
      "source": [
        "In this part of mini-project submission, we will write some code to explain the stack semantics in Trax library. Trax uses many layers in its attempt to make information flow along the layers of a deep network seamless. This short code walk-through helps in understanding the usage of Trax layers like `tl.Select` and `tl.Residual`\r\n",
        "\r\n",
        "We all recall from our Algorithms & Data Structures courses that a stack is a data structure that follows the Last In, First Out (LIFO) principle. That is, whatever is the latest element that is pushed into the stack will also be the first one to be popped out. In this code walkthrough, all one really needs to remember is that a Stack puts elements one on top of the other. We should always be aware of what is on top of the stack to know which element one will be popping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BabFTdq-85dC"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntf6qoTF9d-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c84d84e-7226-4924-da1a-8161cbd0e26b"
      },
      "source": [
        "# Please uncomment the line below and run the command, as I found Colab machines don't have trax library by default\r\n",
        "!pip install trax"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting trax\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/1d/c0a3aeed127c26a0c3f0925fc9cc7278c272e52310eedfc322477e854972/trax-1.3.6-py2.py3-none-any.whl (468kB)\n",
            "\r\u001b[K     |▊                               | 10kB 16.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 20.9MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 102kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 112kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 122kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 143kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 153kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 163kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 174kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 184kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 194kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 204kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 215kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 225kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 235kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 245kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 256kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 266kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 276kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 286kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 296kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 307kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 317kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 327kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 337kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 348kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 358kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 368kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 378kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 389kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 399kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 409kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 419kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 430kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 440kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 450kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 460kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 471kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from trax) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from trax) (4.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from trax) (1.4.1)\n",
            "Collecting funcsigs\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from trax) (0.17.3)\n",
            "Collecting t5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/39/a607d2450190af7675e4f77c5eff0cc9a83f82fe63fb396872ef2004106b/t5-0.7.1-py3-none-any.whl (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 17.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.6/dist-packages (from trax) (0.2.7)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from trax) (0.4.0)\n",
            "Collecting tensorflow-text\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b2/2dbd90b93913afd07e6101b8b84327c401c394e60141c1e98590038060b3/tensorflow_text-2.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 22.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from trax) (0.10.0)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.6/dist-packages (from trax) (0.1.57+cuda101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from trax) (1.18.5)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.1.5)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (1.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.3.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (20.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (2.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (3.12.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (4.41.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.25.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.16.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (3.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->trax) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->trax) (1.3.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 44.0MB/s \n",
            "\u001b[?25hCollecting transformers>=2.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from t5->trax) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from t5->trax) (1.1.5)\n",
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8b/553deb763ce8d00afb17debab7cb14a87b209cd4c6f0e8ecfc8d884cb12a/mesh_tensorflow-0.1.17-py3-none-any.whl (342kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from t5->trax) (1.7.0+cu101)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from t5->trax) (3.2.5)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (from t5->trax) (2.9.0)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n",
            "\u001b[?25hCollecting tfds-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/99/ce83f5cd8c74130ea557422bb0eb7d5dcdb9fb1e115a7748509fa2751fa7/tfds_nightly-4.1.0.dev202012120107-py3-none-any.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from jax->trax) (3.3.0)\n",
            "Requirement already satisfied: tensorflow<2.4,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text->trax) (2.3.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.6/dist-packages (from jaxlib->trax) (1.12)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->trax) (50.3.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.52.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->trax) (3.4.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5->trax) (20.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5->trax) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5->trax) (2019.12.20)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->t5->trax) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->t5->trax) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->t5->trax) (2018.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->t5->trax) (3.7.4.3)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.12.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.36.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.34.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.7.0->t5->trax) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->t5->trax) (7.1.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.7.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (3.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (3.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=0d545c07beebadc15c057dc553208a6c0a8674a9304e62883dc64e3fbf4dfaf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: funcsigs, sentencepiece, tokenizers, sacremoses, transformers, rouge-score, tensorflow-text, mesh-tensorflow, portalocker, sacrebleu, tfds-nightly, t5, trax\n",
            "Successfully installed funcsigs-1.0.2 mesh-tensorflow-0.1.17 portalocker-2.0.0 rouge-score-0.0.4 sacrebleu-1.4.14 sacremoses-0.0.43 sentencepiece-0.1.94 t5-0.7.1 tensorflow-text-2.3.0 tfds-nightly-4.1.0.dev202012120107 tokenizers-0.9.4 transformers-4.0.1 trax-1.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ItNztqHR85dC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144623e9-4468-47b7-c720-86f2216caa72"
      },
      "source": [
        "# Please ignore the warning: Argument blacklist is deprecated. Please use denylist.\n",
        "\n",
        "import numpy as np              # regular ol' numpy\n",
        "from trax import layers as tl   # core building block\n",
        "from trax import shapes         # data signatures: dimensionality and type\n",
        "from trax import fastmath       # uses jax, offers numpy on steroids"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEKkS3dR85dD"
      },
      "source": [
        "## 1. The tl.Serial Combinator is Stack Oriented.\n",
        "\n",
        "To understand how stack-orientation works in [Trax](https://trax-ml.readthedocs.io/en/latest/), most times one will be using the `Serial` layer. We will define two simple [Function layers](https://trax-ml.readthedocs.io/en/latest/notebooks/layers_intro.html?highlight=fn#With-the-Fn-layer-creating-function.): \n",
        "\n",
        "1) Addition and\n",
        "\n",
        "2) Multiplication.\n",
        "\n",
        "Suppose we want to make the simple calculation (3 + 4) * 15 + 3. `Serial` will perform the calculations in the following manner `3` `4` `add` `15` `mul` `3` `add`. The steps of the calculation are shown in the table below. The first column shows the operations made on the stack and the second column the output of those operations. Moreover, the rightmost element in the second column represents the top of the stack (e.g. in the second row, `Push(3)` pushes `3 ` on top of the stack and `4` is now under it).\n",
        "\n",
        "<div style=\"text-align:center\" width=\"50px\"><img src=\"https://github.com/prateekchandrajha/ir-mini-project/blob/main/Stack1.png?raw=1\"/></div>\n",
        "\n",
        "After processing all the stack contains 108 which is the answer to our simple computation.\n",
        "\n",
        "From this, the following can be concluded: \n",
        "- a stack-based layer has only one way to handle data, by taking one piece of data from atop the stack, termed popping, and putting data back atop the stack, termed pushing. \n",
        "- Any expression that can be written conventionally, can be written in this form and thus be amenable to being interpreted by a stack-oriented layer like `tl.Serial`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfVtspSE85dE"
      },
      "source": [
        "### Coding the example in the table attached above:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBnqZHKG85dE"
      },
      "source": [
        "**Defining addition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "DCmdONJI85dE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c714935-1eab-48e1-f045-b41e1d8235d9"
      },
      "source": [
        "def Addition():\n",
        "\n",
        "    layer_name = \"Addition\"  # let's give our custom layer a name to identify\n",
        "\n",
        "    # Custom function for the custom layer\n",
        "    def func(x, y):\n",
        "        return x + y\n",
        "\n",
        "    return tl.Fn(layer_name, func)\n",
        "\n",
        "\n",
        "# Testing it\n",
        "add = Addition()\n",
        "\n",
        "# Inspecting properties of Our Layer\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", add.name)\n",
        "print(\"expected inputs :\", add.n_in)\n",
        "print(\"promised outputs :\", add.n_out, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "x = np.array([3])\n",
        "y = np.array([4])\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x :\", x, \"\\n\")\n",
        "print(\"y :\", y, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "z = add((x, y))\n",
        "print(\"-- Outputs --\")\n",
        "print(\"z :\", z)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- Properties --\n",
            "name : Addition\n",
            "expected inputs : 2\n",
            "promised outputs : 1 \n",
            "\n",
            "-- Inputs --\n",
            "x : [3] \n",
            "\n",
            "y : [4] \n",
            "\n",
            "-- Outputs --\n",
            "z : [7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4WD3JCH85dF"
      },
      "source": [
        "**Defining multiplication**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "QW5x77eG85dF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c319fd1-8bfb-4835-d092-1784851ab5d9"
      },
      "source": [
        "def Multiplication():\n",
        "    layer_name = (\n",
        "        \"Multiplication\"  # don't forget to give your custom layer a name to identify\n",
        "    )\n",
        "\n",
        "    # Custom function for the custom layer\n",
        "    def func(x, y):\n",
        "        return x * y\n",
        "\n",
        "    return tl.Fn(layer_name, func)\n",
        "\n",
        "\n",
        "# Test it\n",
        "mul = Multiplication()\n",
        "\n",
        "# Inspect properties\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", mul.name)\n",
        "print(\"expected inputs :\", mul.n_in)\n",
        "print(\"promised outputs :\", mul.n_out, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "x = np.array([7])\n",
        "y = np.array([15])\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x :\", x, \"\\n\")\n",
        "print(\"y :\", y, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "z = mul((x, y))\n",
        "print(\"-- Outputs --\")\n",
        "print(\"z :\", z)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Properties --\n",
            "name : Multiplication\n",
            "expected inputs : 2\n",
            "promised outputs : 1 \n",
            "\n",
            "-- Inputs --\n",
            "x : [7] \n",
            "\n",
            "y : [15] \n",
            "\n",
            "-- Outputs --\n",
            "z : [105]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB6zDMC985dF"
      },
      "source": [
        "**Implementing the computations using Serial combinator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "4ai4M9Ho85dF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd7eadc-76d0-4d8f-9d8d-24c241d4deb1"
      },
      "source": [
        "# Serial combinator\n",
        "serial = tl.Serial(\n",
        "    Addition(), Multiplication(), Addition()  # add 3 + 4  # multiply result by 15\n",
        ")\n",
        "\n",
        "# Initialization\n",
        "x = (np.array([3]), np.array([4]), np.array([15]), np.array([3]))  # input\n",
        "\n",
        "serial.init(shapes.signature(x))  # initializing serial instance\n",
        "\n",
        "\n",
        "print(\"-- Serial Model --\")\n",
        "print(serial, \"\\n\")\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", serial.name)\n",
        "print(\"sublayers :\", serial.sublayers)\n",
        "print(\"expected inputs :\", serial.n_in)\n",
        "print(\"promised outputs :\", serial.n_out, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x :\", x, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "y = serial(x)\n",
        "print(\"-- Outputs --\")\n",
        "print(\"y :\", y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Serial Model --\n",
            "Serial_in4[\n",
            "  Addition_in2\n",
            "  Multiplication_in2\n",
            "  Addition_in2\n",
            "] \n",
            "\n",
            "-- Properties --\n",
            "name : Serial\n",
            "sublayers : [Addition_in2, Multiplication_in2, Addition_in2]\n",
            "expected inputs : 4\n",
            "promised outputs : 1 \n",
            "\n",
            "-- Inputs --\n",
            "x : (array([3]), array([4]), array([15]), array([3])) \n",
            "\n",
            "-- Outputs --\n",
            "y : [108]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ILi7_ob85dG"
      },
      "source": [
        "The example with the two simple adition and multiplication functions that where coded together with the serial combinator show how stack semantics work in `Trax`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m08psTR-85dG"
      },
      "source": [
        "## 2. The tl.Select combinator in the context of the Serial combinator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr1Wh-SV85dG"
      },
      "source": [
        "Having understood how stack semantics work in `Trax`, we will demonstrate how the [tl.Select](https://trax-ml.readthedocs.io/en/latest/trax.layers.html?highlight=select#trax.layers.combinators.Select) combinator works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jx8XR8L85dG"
      },
      "source": [
        "### First example of tl.Select"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qIVHY5E85dG"
      },
      "source": [
        "Suppose we want to make the simple calculation (3 + 4) * 3 + 4. We can use `Select` to perform the calculations in the following manner:\n",
        "\n",
        "1. `4`\n",
        "2. `3`\n",
        "3. `tl.Select([0,1,0,1])` \n",
        "4. `add` \n",
        "5. `mul` \n",
        "6. `add`. \n",
        "\n",
        "The `tl.Select` requires a list or tuple of 0-based indices to select elements relative to the top of the stack. For our example, the top of the stack is `3` (which is at index 0) then `4` (index 1) and we Select to add in an ordered manner to the top of the stack which after the command is `3` `4` `3` `4`. The steps of the calculation for our example are shown in the table below. As in the previous table each column shows the contents of the stack and the outputs after the operations are carried out.\n",
        "\n",
        "<div style=\"text-align:center\" width=\"20px\"><img src=\"https://github.com/prateekchandrajha/ir-mini-project/blob/main/Stack2.png?raw=1\" /></div>\n",
        "\n",
        "After processing all the inputs the stack contains 25 which is the answer we get above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "RongkEoF85dH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3edce31-4e41-466c-fc73-2ec13e7866a9"
      },
      "source": [
        "serial = tl.Serial(tl.Select([0, 1, 0, 1]), Addition(), Multiplication(), Addition())\n",
        "\n",
        "# Initialization\n",
        "x = (np.array([3]), np.array([4]))  # input\n",
        "\n",
        "serial.init(shapes.signature(x))  # initializing serial instance\n",
        "\n",
        "\n",
        "print(\"-- Serial Model --\")\n",
        "print(serial, \"\\n\")\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", serial.name)\n",
        "print(\"sublayers :\", serial.sublayers)\n",
        "print(\"expected inputs :\", serial.n_in)\n",
        "print(\"promised outputs :\", serial.n_out, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x :\", x, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "y = serial(x)\n",
        "print(\"-- Outputs --\")\n",
        "print(\"y :\", y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Serial Model --\n",
            "Serial_in2[\n",
            "  Select[0,1,0,1]_in2_out4\n",
            "  Addition_in2\n",
            "  Multiplication_in2\n",
            "  Addition_in2\n",
            "] \n",
            "\n",
            "-- Properties --\n",
            "name : Serial\n",
            "sublayers : [Select[0,1,0,1]_in2_out4, Addition_in2, Multiplication_in2, Addition_in2]\n",
            "expected inputs : 2\n",
            "promised outputs : 1 \n",
            "\n",
            "-- Inputs --\n",
            "x : (array([3]), array([4])) \n",
            "\n",
            "-- Outputs --\n",
            "y : [25]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rb-JaDh85dH"
      },
      "source": [
        "### Second example of tl.Select"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAhnHSms85dI"
      },
      "source": [
        "Suppose we want to make the simple calculation (3 + 4) * 4. We can use `Select` to perform the calculations in the following manner:\n",
        "\n",
        "1. `4`\n",
        "2. `3`\n",
        "3. `tl.Select([0,1,0,1])` \n",
        "4. `add` \n",
        "5. `tl.Select([0], n_in=2)`\n",
        "6. `mul`\n",
        "\n",
        "The example is a bit contrived but it demonstrates the flexibility of the command. The second `tl.Select` pops two elements (specified in n_in) from the stack starting from index 0 (i.e. top of the stack). This means that `7` and `3 ` will be popped out because `n_in = 2`) but only `7` is placed back on top because it only selects `[0]`.  As in the previous table each column shows the contents of the stack and the outputs after the operations are carried out.\n",
        "\n",
        "<div style=\"text-align:center\" width=\"20px\"><img src=\"https://github.com/prateekchandrajha/ir-mini-project/blob/main/Stack3.png?raw=1\" /></div>\n",
        "\n",
        "After processing all the inputs the stack contains 28 which is the answer we get above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "AEb2hH5r85dI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d358d7d-d3b3-4ead-cb0d-76f0231ab42e"
      },
      "source": [
        "serial = tl.Serial(\n",
        "    tl.Select([0, 1, 0, 1]), Addition(), tl.Select([0], n_in=2), Multiplication()\n",
        ")\n",
        "\n",
        "# Initialization\n",
        "x = (np.array([3]), np.array([4]))  # input\n",
        "\n",
        "serial.init(shapes.signature(x))  # initializing serial instance\n",
        "\n",
        "\n",
        "print(\"-- Serial Model --\")\n",
        "print(serial, \"\\n\")\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", serial.name)\n",
        "print(\"sublayers :\", serial.sublayers)\n",
        "print(\"expected inputs :\", serial.n_in)\n",
        "print(\"promised outputs :\", serial.n_out, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x :\", x, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "y = serial(x)\n",
        "print(\"-- Outputs --\")\n",
        "print(\"y :\", y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Serial Model --\n",
            "Serial_in2[\n",
            "  Select[0,1,0,1]_in2_out4\n",
            "  Addition_in2\n",
            "  Select[0]_in2\n",
            "  Multiplication_in2\n",
            "] \n",
            "\n",
            "-- Properties --\n",
            "name : Serial\n",
            "sublayers : [Select[0,1,0,1]_in2_out4, Addition_in2, Select[0]_in2, Multiplication_in2]\n",
            "expected inputs : 2\n",
            "promised outputs : 1 \n",
            "\n",
            "-- Inputs --\n",
            "x : (array([3]), array([4])) \n",
            "\n",
            "-- Outputs --\n",
            "y : [28]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2NgFmN185dI"
      },
      "source": [
        "**In summary, what Select does in this example is a copy of the inputs in order to be used further along in the stack of operations.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7hOnuxR85dI"
      },
      "source": [
        "## 3. The tl.Residual combinator in the context of the Serial combinator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fEwU5El85dI"
      },
      "source": [
        "### tl.Residual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4EfCkLG85dJ"
      },
      "source": [
        "[Residual networks](https://arxiv.org/pdf/1512.03385.pdf) are frequently used to make deep models easier to train and you will be using it in the assignment as well. Trax already has a built in layer for this. The [Residual layer](https://trax-ml.readthedocs.io/en/latest/trax.layers.html?highlight=residual#trax.layers.combinators.Residual) computes the element-wise sum of the *stack-top* input with the output of the layer series. For example, if we wanted the cumulative sum of the folowing series of computations (3 + 4) * 3 + 4. The result can be obtained with the use of the `Residual` combinator in the following manner \n",
        "\n",
        "1. `4`\n",
        "2. `3`\n",
        "3. `tl.Select([0,1,0,1])` \n",
        "4. `add` \n",
        "5. `mul` \n",
        "6. `tl.Residual`.  \n",
        "\n",
        "For our example the top of the stack is `3` `4` and we select to add the same to numbers in an ordered manner to the top of the stack which after the command is `3` `4` `3` `4`. The steps of the calculation for our example are shown in the table below together with the cumulative sum which is the result of `tl.Residual`.\n",
        "\n",
        "<div style=\"text-align:center\" width=\"20px\"><img src=\"https://github.com/amanchadha/coursera-natural-language-processing-specialization/blob/master/4%20-%20Natural%20Language%20Processing%20with%20Attention%20Models/Week%201/Stack4.png?raw=1\" /></div>\n",
        "\n",
        "After processing all the inputs the stack contains 50 which is the cumulative sum of all the operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "tags": [],
        "id": "6vsUIcO_85dJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f874070-d218-42d4-91dc-e4b0f81142c2"
      },
      "source": [
        "serial = tl.Serial(\n",
        "    tl.Select([0, 1, 0, 1]), Addition(), Multiplication(), Addition(), tl.Residual()\n",
        ")\n",
        "\n",
        "# Initialization\n",
        "x = (np.array([3]), np.array([4]))  # input\n",
        "\n",
        "serial.init(shapes.signature(x))  # initializing serial instance\n",
        "\n",
        "\n",
        "print(\"-- Serial Model --\")\n",
        "print(serial, \"\\n\")\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", serial.name)\n",
        "print(\"sublayers :\", serial.sublayers)\n",
        "print(\"expected inputs :\", serial.n_in)\n",
        "print(\"promised outputs :\", serial.n_out, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x :\", x, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "y = serial(x)\n",
        "print(\"-- Outputs --\")\n",
        "print(\"y :\", y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Serial Model --\n",
            "Serial_in2[\n",
            "  Select[0,1,0,1]_in2_out4\n",
            "  Addition_in2\n",
            "  Multiplication_in2\n",
            "  Addition_in2\n",
            "  Serial[\n",
            "    Branch_out2[\n",
            "      None\n",
            "      Serial\n",
            "    ]\n",
            "    Add_in2\n",
            "  ]\n",
            "] \n",
            "\n",
            "-- Properties --\n",
            "name : Serial\n",
            "sublayers : [Select[0,1,0,1]_in2_out4, Addition_in2, Multiplication_in2, Addition_in2, Serial[\n",
            "  Branch_out2[\n",
            "    None\n",
            "    Serial\n",
            "  ]\n",
            "  Add_in2\n",
            "]]\n",
            "expected inputs : 2\n",
            "promised outputs : 1 \n",
            "\n",
            "-- Inputs --\n",
            "x : (array([3]), array([4])) \n",
            "\n",
            "-- Outputs --\n",
            "y : [50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEdxQvVf85dJ"
      },
      "source": [
        "### A slightly trickier example:\n",
        "\n",
        "Normally, the Residual layer will accept a layer as an argument and it will add the output of that layer to the current stack top input. In the example below, you'll notice that in the last step, we specify `tl.Residual(Addition())`. If you refer to the same figure above, you'll notice that the stack at that point has `21 4` where `21` is the top of the stack. The Residual layer remembers this value (i.e. `21`) so the result of the `Addition()` layer nested into it (i.e. `25`) is added to this stack top input to arrive at the result: `46`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO9pyGR485dK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf1bb67-05be-47a8-dc1a-1f46ea6ca819"
      },
      "source": [
        "serial = tl.Serial(\n",
        "    tl.Select([0, 1, 0, 1]), Addition(), Multiplication(), tl.Residual(Addition()) \n",
        ")\n",
        "\n",
        "# Initialization\n",
        "x = (np.array([3]), np.array([4]))  # input\n",
        "\n",
        "serial.init(shapes.signature(x))  # initializing serial instance\n",
        "\n",
        "\n",
        "print(\"-- Serial Model --\")\n",
        "print(serial, \"\\n\")\n",
        "print(\"-- Properties --\")\n",
        "print(\"name :\", serial.name)\n",
        "print(\"sublayers :\", serial.sublayers)\n",
        "print(\"------------------------------------------------------\")\n",
        "print(\"expected inputs :\", serial.n_in)\n",
        "print(\"promised outputs :\", serial.n_out, \"\\n\")\n",
        "\n",
        "# Inputs\n",
        "print(\"-- Inputs --\")\n",
        "print(\"x :\", x, \"\\n\")\n",
        "\n",
        "# Outputs\n",
        "y = serial(x)\n",
        "print(\"-- Outputs --\")\n",
        "print(\"y :\", y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Serial Model --\n",
            "Serial_in2[\n",
            "  Select[0,1,0,1]_in2_out4\n",
            "  Addition_in2\n",
            "  Multiplication_in2\n",
            "  Serial_in2[\n",
            "    Branch_in2_out2[\n",
            "      None\n",
            "      Addition_in2\n",
            "    ]\n",
            "    Add_in2\n",
            "  ]\n",
            "] \n",
            "\n",
            "-- Properties --\n",
            "name : Serial\n",
            "sublayers : [Select[0,1,0,1]_in2_out4, Addition_in2, Multiplication_in2, Serial_in2[\n",
            "  Branch_in2_out2[\n",
            "    None\n",
            "    Addition_in2\n",
            "  ]\n",
            "  Add_in2\n",
            "]]\n",
            "------------------------------------------------------\n",
            "expected inputs : 2\n",
            "promised outputs : 1 \n",
            "\n",
            "-- Inputs --\n",
            "x : (array([3]), array([4])) \n",
            "\n",
            "-- Outputs --\n",
            "y : [46]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}